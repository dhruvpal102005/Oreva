{
  "version": 3,
  "sources": ["../../../aws/lambda/scanner/index.ts"],
  "sourcesContent": ["import { APIGatewayProxyHandler } from 'aws-lambda';\r\n\r\nexport const handler: APIGatewayProxyHandler = async (event) => {\r\n    console.log(\"Received scan request\");\r\n\r\n    try {\r\n        if (!event.body) {\r\n            return { statusCode: 400, body: JSON.stringify({ error: \"No body provided\" }) };\r\n        }\r\n\r\n        const { owner, repo, token, apiKey } = JSON.parse(event.body);\r\n\r\n        if (!owner || !repo || !token || !apiKey) {\r\n            return { statusCode: 400, body: JSON.stringify({ error: \"Missing required fields: owner, repo, token, apiKey (for Gemini)\" }) };\r\n        }\r\n\r\n        // 1. Fetch File Content from GitHub\r\n        const files = await fetchRepoFiles(token, owner, repo);\r\n        const codeFiles = files.filter((f: any) => /\\.(js|ts|tsx|jsx|py|go|rs|java|sol)$/.test(f.path));\r\n\r\n        console.log(`Found ${codeFiles.length} code files. Fetching content...`);\r\n\r\n        // Limit to 10 files\r\n        const fileContents = await Promise.all(\r\n            codeFiles.slice(0, 10).map((f: any) => fetchFileContent(token, owner, repo, f.path))\r\n        );\r\n\r\n        // 2. Construct Prompt\r\n        const prompt = constructPrompt(fileContents);\r\n\r\n        // 3. Invoke Google Gemini (REST API)\r\n        console.log(\"Invoking Google Gemini...\");\r\n        const response = await fetch(\r\n            `https://generativelanguage.googleapis.com/v1/models/gemini-2.5-flash:generateContent?key=${apiKey}`,\r\n            {\r\n                method: 'POST',\r\n                headers: { 'Content-Type': 'application/json' },\r\n                body: JSON.stringify({\r\n                    contents: [{\r\n                        parts: [{ text: prompt }]\r\n                    }]\r\n                })\r\n            }\r\n        );\r\n\r\n        if (!response.ok) {\r\n            const errorText = await response.text();\r\n            console.error(\"Gemini API error:\", errorText);\r\n            throw new Error(`Gemini API error: ${response.status} - ${errorText}`);\r\n        }\r\n\r\n        const data = await response.json();\r\n        const aiText = data.candidates[0].content.parts[0].text;\r\n\r\n        const scanResult = parseResponse(aiText);\r\n\r\n        return {\r\n            statusCode: 200,\r\n            body: JSON.stringify(scanResult),\r\n            headers: { \"Content-Type\": \"application/json\" }\r\n        };\r\n\r\n    } catch (error: any) {\r\n        console.error(\"Lambda Scan Failed:\", error);\r\n        return {\r\n            statusCode: 500,\r\n            body: JSON.stringify({ error: error.message || \"Internal Server Error\" })\r\n        };\r\n    }\r\n};\r\n\r\n// --- Helper Functions ---\r\n\r\nasync function fetchRepoFiles(token: string, owner: string, repo: string, path = \"\"): Promise<any[]> {\r\n    console.log(`Fetching files from: https://api.github.com/repos/${owner}/${repo}/contents/${path}`);\r\n    const res = await fetch(`https://api.github.com/repos/${owner}/${repo}/contents/${path}`, {\r\n        headers: {\r\n            Authorization: `Bearer ${token}`,\r\n            \"User-Agent\": \"Oreva-Scanner-Lambda\",\r\n            \"Accept\": \"application/vnd.github.v3+json\"\r\n        }\r\n    });\r\n    if (!res.ok) {\r\n        const errorBody = await res.text();\r\n        console.error(`GitHub Fetch Failed (${res.status}):`, errorBody);\r\n        throw new Error(`GitHub Fetch Failed: ${res.statusText} (${res.status}) - ${errorBody}`);\r\n    }\r\n\r\n    const data = await res.json();\r\n    let files: any[] = [];\r\n    if (Array.isArray(data)) {\r\n        for (const item of data) {\r\n            if (item.type === \"file\") files.push(item);\r\n        }\r\n    }\r\n    return files;\r\n}\r\n\r\nasync function fetchFileContent(token: string, owner: string, repo: string, path: string): Promise<{ path: string, content: string }> {\r\n    const res = await fetch(`https://api.github.com/repos/${owner}/${repo}/contents/${path}`, {\r\n        headers: {\r\n            Authorization: `Bearer ${token}`,\r\n            \"User-Agent\": \"Oreva-Scanner-Lambda\",\r\n            \"Accept\": \"application/vnd.github.v3+json\"\r\n        }\r\n    });\r\n\r\n    if (!res.ok) {\r\n        const errorBody = await res.text();\r\n        console.error(`GitHub Content Fetch Failed (${res.status}):`, errorBody);\r\n        throw new Error(`GitHub Content Fetch Failed: ${res.statusText}`);\r\n    }\r\n\r\n    const data = await res.json();\r\n    const content = Buffer.from(data.content, \"base64\").toString(\"utf-8\");\r\n    return { path, content };\r\n}\r\n\r\nfunction constructPrompt(files: { path: string, content: string }[]): string {\r\n    let codeContext = \"\";\r\n    for (const file of files) {\r\n        codeContext += `\\n--- FILE: ${file.path} ---\\n${file.content}\\n`;\r\n    }\r\n\r\n    return `\r\n    You are an expert Cyber Security Analyst. Analyze the following code for security vulnerabilities.\r\n    \r\n    Code Context:\r\n    ${codeContext}\r\n\r\n    Output Format: JSON object with \"findings\" (array) and \"summary\" (string).\r\n    Each finding should have:\r\n    - type: string (e.g., \"SQL Injection\", \"XSS\", \"Dependency Vulnerability\")\r\n    - name: string (short title, max 50 characters)\r\n    - severity: \"Critical\" | \"High\" | \"Medium\" | \"Low\"\r\n    - location: string (file path)\r\n    - description: string (ONE LINE ONLY, max 80 characters, concise explanation)\r\n    - fix: string (brief fix suggestion, max 150 characters)\r\n    - fixTime: string (estimated time, e.g., \"30 min\", \"1 hr\", \"2 hr\")\r\n    - detailedAnalysis: string (optional, detailed explanation)\r\n    - subIssues: array (optional, for dependencies) with {id, cve, severity, package, version, analysis}\r\n\r\n    IMPORTANT: \r\n    - Keep descriptions very short and concise (one line, max 80 characters).\r\n    - For dependency vulnerabilities (Next.js, React), include subIssues with CVE info.\r\n    - Return ONLY valid JSON.\r\n    `;\r\n}\r\n\r\nfunction parseResponse(text: string): any {\r\n    try {\r\n        const cleanText = text.replace(/```json/g, \"\").replace(/```/g, \"\").trim();\r\n        return JSON.parse(cleanText);\r\n    } catch (e) {\r\n        console.error(\"Parse error:\", e);\r\n        return { findings: [], summary: \"Failed to parse analysis results.\" };\r\n    }\r\n}\r\n"],
  "mappings": "yaAAA,IAAAA,EAAA,GAAAC,EAAAD,EAAA,aAAAE,IAAA,eAAAC,EAAAH,GAEO,IAAME,EAAkC,MAAOE,GAAU,CAC5D,QAAQ,IAAI,uBAAuB,EAEnC,GAAI,CACA,GAAI,CAACA,EAAM,KACP,MAAO,CAAE,WAAY,IAAK,KAAM,KAAK,UAAU,CAAE,MAAO,kBAAmB,CAAC,CAAE,EAGlF,GAAM,CAAE,MAAAC,EAAO,KAAAC,EAAM,MAAAC,EAAO,OAAAC,CAAO,EAAI,KAAK,MAAMJ,EAAM,IAAI,EAE5D,GAAI,CAACC,GAAS,CAACC,GAAQ,CAACC,GAAS,CAACC,EAC9B,MAAO,CAAE,WAAY,IAAK,KAAM,KAAK,UAAU,CAAE,MAAO,kEAAmE,CAAC,CAAE,EAKlI,IAAMC,GADQ,MAAMC,EAAeH,EAAOF,EAAOC,CAAI,GAC7B,OAAQK,GAAW,uCAAuC,KAAKA,EAAE,IAAI,CAAC,EAE9F,QAAQ,IAAI,SAASF,EAAU,MAAM,kCAAkC,EAGvE,IAAMG,EAAe,MAAM,QAAQ,IAC/BH,EAAU,MAAM,EAAG,EAAE,EAAE,IAAKE,GAAWE,EAAiBN,EAAOF,EAAOC,EAAMK,EAAE,IAAI,CAAC,CACvF,EAGMG,EAASC,EAAgBH,CAAY,EAG3C,QAAQ,IAAI,2BAA2B,EACvC,IAAMI,EAAW,MAAM,MACnB,4FAA4FR,CAAM,GAClG,CACI,OAAQ,OACR,QAAS,CAAE,eAAgB,kBAAmB,EAC9C,KAAM,KAAK,UAAU,CACjB,SAAU,CAAC,CACP,MAAO,CAAC,CAAE,KAAMM,CAAO,CAAC,CAC5B,CAAC,CACL,CAAC,CACL,CACJ,EAEA,GAAI,CAACE,EAAS,GAAI,CACd,IAAMC,EAAY,MAAMD,EAAS,KAAK,EACtC,cAAQ,MAAM,oBAAqBC,CAAS,EACtC,IAAI,MAAM,qBAAqBD,EAAS,MAAM,MAAMC,CAAS,EAAE,CACzE,CAGA,IAAMC,GADO,MAAMF,EAAS,KAAK,GACb,WAAW,CAAC,EAAE,QAAQ,MAAM,CAAC,EAAE,KAE7CG,EAAaC,EAAcF,CAAM,EAEvC,MAAO,CACH,WAAY,IACZ,KAAM,KAAK,UAAUC,CAAU,EAC/B,QAAS,CAAE,eAAgB,kBAAmB,CAClD,CAEJ,OAASE,EAAY,CACjB,eAAQ,MAAM,sBAAuBA,CAAK,EACnC,CACH,WAAY,IACZ,KAAM,KAAK,UAAU,CAAE,MAAOA,EAAM,SAAW,uBAAwB,CAAC,CAC5E,CACJ,CACJ,EAIA,eAAeX,EAAeH,EAAeF,EAAeC,EAAcgB,EAAO,GAAoB,CACjG,QAAQ,IAAI,qDAAqDjB,CAAK,IAAIC,CAAI,aAAagB,CAAI,EAAE,EACjG,IAAMC,EAAM,MAAM,MAAM,gCAAgClB,CAAK,IAAIC,CAAI,aAAagB,CAAI,GAAI,CACtF,QAAS,CACL,cAAe,UAAUf,CAAK,GAC9B,aAAc,uBACd,OAAU,gCACd,CACJ,CAAC,EACD,GAAI,CAACgB,EAAI,GAAI,CACT,IAAMC,EAAY,MAAMD,EAAI,KAAK,EACjC,cAAQ,MAAM,wBAAwBA,EAAI,MAAM,KAAMC,CAAS,EACzD,IAAI,MAAM,wBAAwBD,EAAI,UAAU,KAAKA,EAAI,MAAM,OAAOC,CAAS,EAAE,CAC3F,CAEA,IAAMC,EAAO,MAAMF,EAAI,KAAK,EACxBG,EAAe,CAAC,EACpB,GAAI,MAAM,QAAQD,CAAI,EAClB,QAAWE,KAAQF,EACXE,EAAK,OAAS,QAAQD,EAAM,KAAKC,CAAI,EAGjD,OAAOD,CACX,CAEA,eAAeb,EAAiBN,EAAeF,EAAeC,EAAcgB,EAA0D,CAClI,IAAMC,EAAM,MAAM,MAAM,gCAAgClB,CAAK,IAAIC,CAAI,aAAagB,CAAI,GAAI,CACtF,QAAS,CACL,cAAe,UAAUf,CAAK,GAC9B,aAAc,uBACd,OAAU,gCACd,CACJ,CAAC,EAED,GAAI,CAACgB,EAAI,GAAI,CACT,IAAMC,EAAY,MAAMD,EAAI,KAAK,EACjC,cAAQ,MAAM,gCAAgCA,EAAI,MAAM,KAAMC,CAAS,EACjE,IAAI,MAAM,gCAAgCD,EAAI,UAAU,EAAE,CACpE,CAEA,IAAME,EAAO,MAAMF,EAAI,KAAK,EACtBK,EAAU,OAAO,KAAKH,EAAK,QAAS,QAAQ,EAAE,SAAS,OAAO,EACpE,MAAO,CAAE,KAAAH,EAAM,QAAAM,CAAQ,CAC3B,CAEA,SAASb,EAAgBW,EAAoD,CACzE,IAAIG,EAAc,GAClB,QAAWC,KAAQJ,EACfG,GAAe;AAAA,YAAeC,EAAK,IAAI;AAAA,EAASA,EAAK,OAAO;AAAA,EAGhE,MAAO;AAAA;AAAA;AAAA;AAAA,MAILD,CAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAmBjB,CAEA,SAAST,EAAcW,EAAmB,CACtC,GAAI,CACA,IAAMC,EAAYD,EAAK,QAAQ,WAAY,EAAE,EAAE,QAAQ,OAAQ,EAAE,EAAE,KAAK,EACxE,OAAO,KAAK,MAAMC,CAAS,CAC/B,OAASC,EAAG,CACR,eAAQ,MAAM,eAAgBA,CAAC,EACxB,CAAE,SAAU,CAAC,EAAG,QAAS,mCAAoC,CACxE,CACJ",
  "names": ["scanner_exports", "__export", "handler", "__toCommonJS", "event", "owner", "repo", "token", "apiKey", "codeFiles", "fetchRepoFiles", "f", "fileContents", "fetchFileContent", "prompt", "constructPrompt", "response", "errorText", "aiText", "scanResult", "parseResponse", "error", "path", "res", "errorBody", "data", "files", "item", "content", "codeContext", "file", "text", "cleanText", "e"]
}
